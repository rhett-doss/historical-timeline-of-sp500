{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from datetime import timedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess current sp500 and sp500 component changes\n",
    "# wiki_sp = current sp500\n",
    "# wiki_change = wiki sp500 component changes\n",
    "# sp_historic = sp500 component list since 2011\n",
    "def read_and_preprocess(url, sp_historic_path):\n",
    "    table1 = pd.read_html(url)\n",
    "    wiki_sp = table1[0]\n",
    "    wiki_sp = wiki_sp[['Symbol']]\n",
    "\n",
    "    table2 = pd.read_html(url, header=0)\n",
    "    wiki_change = table1[1]\n",
    "    \n",
    "    sp_historic = pd.read_csv(sp_historic_path, sep='|')\n",
    "    sp_historic['date'] = pd.to_datetime(sp_historic['date'])\n",
    "    sp_historic['tickers'] = sp_historic['tickers'].apply(lambda x: sorted(x.split(',')))\n",
    "    \n",
    "    return wiki_sp, wiki_change, sp_historic\n",
    "\n",
    "\n",
    "def wiki_change_formatting(wiki_change):\n",
    "    # Drop extra header and unwanted cols\n",
    "    wiki_change = wiki_change.reset_index(drop=True)\n",
    "    wiki_change = wiki_change.drop(['Reason', 'Security'], axis=1, level=1)\n",
    "    bottom_headers = wiki_change.columns.get_level_values(0)\n",
    "    top_headers = wiki_change.columns.get_level_values(1)\n",
    "    wiki_change.columns = bottom_headers\n",
    "    # Rename Cols\n",
    "    wiki_change = wiki_change.rename(columns={'Date': 'date', 'Added': 'added', 'Removed': 'removed'})\n",
    "    # Fix date format\n",
    "    wiki_change['date'] = pd.to_datetime(wiki_change['date'])\n",
    "    wiki_change['date'] = wiki_change['date'].dt.strftime('%Y-%m-%d')\n",
    "    wiki_change['date'] = pd.to_datetime(wiki_change['date'])\n",
    "    # Filter off dates before current date\n",
    "    wiki_change = wiki_change.loc[wiki_change['date'] >= pd.to_datetime('2023-06-21')]\n",
    "    # Replace NaN values with None in 'Added' and 'Removed' columns\n",
    "    wiki_change['added'] = wiki_change['added'].fillna('None')\n",
    "    wiki_change['removed'] = wiki_change['removed'].fillna('None')\n",
    "    # Group by 'Date' column and combine 'Added' and 'Removed' values as a list\n",
    "    wiki_change = wiki_change.groupby('date').agg(lambda x: x.tolist()).reset_index()\n",
    "    # Sort by date\n",
    "    wiki_change = wiki_change.sort_values(by='date', ascending=True)\n",
    "    wiki_change = wiki_change.reset_index(drop=True)\n",
    "    \n",
    "    return wiki_change\n",
    "\n",
    "# Update sp_historic with changes from wiki_change    \n",
    "def historic_data_process(wiki_change, sp_historic):\n",
    "    for change in wiki_change.itertuples():\n",
    "        # Assign values\n",
    "        date = change.date\n",
    "        added_tickers = change.added\n",
    "        removed_tickers = change.removed\n",
    "\n",
    "        new_row = sp_historic.tail(1)\n",
    "        tickers = list(new_row['tickers'].values[0])\n",
    "\n",
    "        # Skip over 'None' values and proceed to next valid symbol in added_tickers\n",
    "        index = 0\n",
    "        while index < len(added_tickers):\n",
    "            ticker = added_tickers[index]\n",
    "            if ticker == 'None':\n",
    "                index += 1\n",
    "                continue\n",
    "            tickers.append(ticker)\n",
    "            index += 1\n",
    "\n",
    "        # Add or remove tickers in list    \n",
    "        tickers = list(set(tickers) - set(removed_tickers))\n",
    "        tickers = sorted(tickers)\n",
    "\n",
    "        # Store updates & concat\n",
    "        d = {'date': date, 'tickers': [tickers]}\n",
    "        new_entry = pd.DataFrame(d)\n",
    "        sp_historic = pd.concat([sp_historic, new_entry]).reset_index(drop=True)\n",
    "        \n",
    "    # Define ticker replacements\n",
    "    ticker_replacements = {\n",
    "    'PKI': 'RVTY',\n",
    "    'FISV': 'FI',\n",
    "    'RE': 'EG'\n",
    "    }\n",
    "    # Replace tickers with updated tickers\n",
    "    sp_historic['tickers'] = sp_historic['tickers'].apply(lambda x: sorted([ticker_replacements.get(ticker, ticker) for ticker in x]))\n",
    "    \n",
    "    # Formatting\n",
    "    # Fix date format\n",
    "    sp_historic['date'] = pd.to_datetime(sp_historic['date'])\n",
    "    sp_historic['date'] = sp_historic['date'].dt.strftime('%Y-%m-%d')\n",
    "    sp_historic['date'] = pd.to_datetime(sp_historic['date'])\n",
    "    sp_historic = sp_historic.sort_values(by='date')\n",
    "    # Resample with daily frequency\n",
    "    # Set 'date' column as the index\n",
    "    #sp_historic = sp_historic.set_index('date')\n",
    "    # Resample the dataframe with daily frequency and forward fill the missing values\n",
    "    #sp_historic = sp_historic.resample('D').ffill()\n",
    "    # Reset the index and restore 'date' as a column\n",
    "    #sp_historic = sp_historic.reset_index()\n",
    "    #sp_historic = sp_historic.sort_values('date')\n",
    "    \n",
    "    return sp_historic\n",
    "\n",
    "# Update sp_historic with corp actions\n",
    "def process_corporate_actions(sp_historic, s_changes_path):\n",
    "    # Update sp historic with corporate action ticker changes\n",
    "    s_changes = pd.read_csv(s_changes_path, sep='|')\n",
    "    s_changes = s_changes.sort_values(by='date', ascending=False)\n",
    "    s_changes = s_changes[s_changes['date'] <= '2023-06-20']\n",
    "    s_changes = s_changes.reset_index(drop=True)\n",
    "\n",
    "    # Group changes by day\n",
    "    grouped_changes = s_changes.groupby('date')\n",
    "\n",
    "    # Iterate over each day going back in time\n",
    "    for date, group in reversed(list(grouped_changes)):\n",
    "\n",
    "        # Get tickers for the day before the change date\n",
    "        prev_date = pd.to_datetime(date) - pd.DateOffset(days=1)\n",
    "        prev_day_tickers = sp_historic.loc[sp_historic['date'] == prev_date, 'tickers']\n",
    "        if prev_day_tickers.empty:\n",
    "            break\n",
    "        prev_day_tickers = prev_day_tickers.iloc[0]\n",
    "\n",
    "        removed_tickers = []\n",
    "        added_tickers = []\n",
    "        for index, row in group.iterrows():\n",
    "            symbol = row['symbol']\n",
    "            prev_symbol = row['prev_symbol']\n",
    "            if symbol in prev_day_tickers:\n",
    "                removed_tickers.append(symbol)\n",
    "                added_tickers.append(prev_symbol)\n",
    "\n",
    "        removed_tickers = set(removed_tickers)\n",
    "        added_tickers = set(added_tickers)\n",
    "    \n",
    "        # Find tickers only added or removed\n",
    "        unique_added = added_tickers - removed_tickers\n",
    "        unique_removed = removed_tickers - added_tickers\n",
    "\n",
    "        def corporate_action(row, unique_added, unique_removed, prev_day_tickers):\n",
    "            tickers = row\n",
    "            updated_tickers = list(set(tickers) - set(unique_removed))\n",
    "            updated_tickers += unique_added\n",
    "            return sorted(updated_tickers)\n",
    "            \n",
    "        # Update tickers in sp_historic for current day\n",
    "        sp_historic.loc[sp_historic['date'] < date, 'tickers'] = sp_historic.loc[sp_historic['date'] < date, 'tickers'].apply(lambda x: corporate_action(x, unique_added, unique_removed, prev_day_tickers))\n",
    "\n",
    "    # Sort sp_historic by date\n",
    "    sp_historic = sp_historic.sort_values(by='date').reset_index(drop=True)\n",
    "    \n",
    "    return sp_historic\n",
    "\n",
    "\n",
    "def main(url, sp_historical_path, s_changes_path):\n",
    "    wiki_sp, wiki_change, sp_historic = read_and_preprocess(url, sp_historic_path)\n",
    "    wiki_change = wiki_change_formatting(wiki_change)\n",
    "    sp_historic = historic_data_process(wiki_change, sp_historic)\n",
    "    \n",
    "    # Update with previous tickers if no changes from wiki sp\n",
    "    # Get today's date\n",
    "    today = pd.to_datetime('today').normalize()\n",
    "\n",
    "    # If the latest date in the data is before today, append today's data\n",
    "    if sp_historic['date'].iloc[-1] < today:\n",
    "        last_tickers = sp_historic['tickers'].iloc[-1]\n",
    "        new_row = {'date': today, 'tickers': last_tickers}\n",
    "        sp_historic = sp_historic.append(new_row, ignore_index=True)\n",
    "    \n",
    "    sp_historic = process_corporate_actions(sp_historic, s_changes_path)\n",
    "    \n",
    "    return sp_historic\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    sp_historic_path = '/home/rdoss/list_fixes/sp500_fix/output_check'\n",
    "    s_changes_path = '/home/rdoss/list_fixes/sp500_fix/ticker_changes.csv'\n",
    "    sp_historic = main(url, sp_historic_path, s_changes_path)\n",
    "    \n",
    "    print(sp_historic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
