{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from datetime import timedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43577/7454910.py:165: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sp_historic = sp_historic.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 175\u001b[0m\n\u001b[1;32m    173\u001b[0m sp_historic_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/rdoss/list_fixes/sp500_fix/output_check\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    174\u001b[0m s_changes_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/rdoss/list_fixes/sp500_fix/ticker_changes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 175\u001b[0m sp_historic \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msp_historic_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_changes_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mprint\u001b[39m(sp_historic)\n",
      "Cell \u001b[0;32mIn[48], line 167\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(url, sp_historical_path, s_changes_path)\u001b[0m\n\u001b[1;32m    164\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: today, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtickers\u001b[39m\u001b[38;5;124m'\u001b[39m: last_tickers}\n\u001b[1;32m    165\u001b[0m     sp_historic \u001b[38;5;241m=\u001b[39m sp_historic\u001b[38;5;241m.\u001b[39mappend(new_row, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 167\u001b[0m sp_historic \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_corporate_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43msp_historic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_changes_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sp_historic\n",
      "Cell \u001b[0;32mIn[48], line 144\u001b[0m, in \u001b[0;36mprocess_corporate_actions\u001b[0;34m(sp_historic, s_changes_path)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(updated_tickers)\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# Update tickers in sp_historic for current day\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     sp_historic\u001b[38;5;241m.\u001b[39mloc[sp_historic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtickers\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msp_historic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43msp_historic\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtickers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorporate_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_added\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_removed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_day_tickers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Sort sp_historic by date\u001b[39;00m\n\u001b[1;32m    147\u001b[0m sp_historic \u001b[38;5;241m=\u001b[39m sp_historic\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[48], line 144\u001b[0m, in \u001b[0;36mprocess_corporate_actions.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(updated_tickers)\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# Update tickers in sp_historic for current day\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     sp_historic\u001b[38;5;241m.\u001b[39mloc[sp_historic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtickers\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sp_historic\u001b[38;5;241m.\u001b[39mloc[sp_historic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtickers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcorporate_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_added\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_removed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_day_tickers\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Sort sp_historic by date\u001b[39;00m\n\u001b[1;32m    147\u001b[0m sp_historic \u001b[38;5;241m=\u001b[39m sp_historic\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[48], line 139\u001b[0m, in \u001b[0;36mprocess_corporate_actions.<locals>.corporate_action\u001b[0;34m(row, unique_added, unique_removed, prev_day_tickers)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorporate_action\u001b[39m(row, unique_added, unique_removed, prev_day_tickers):\n\u001b[1;32m    138\u001b[0m     tickers \u001b[38;5;241m=\u001b[39m row\n\u001b[0;32m--> 139\u001b[0m     updated_tickers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_removed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     updated_tickers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m unique_added\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(updated_tickers)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Preprocess current sp500 and sp500 component changes\n",
    "# wiki_sp = current sp500\n",
    "# wiki_change = wiki sp500 component changes\n",
    "# sp_historic = sp500 component list since 2011\n",
    "def read_and_preprocess(url, sp_historic_path):\n",
    "    table1 = pd.read_html(url)\n",
    "    wiki_sp = table1[0]\n",
    "    wiki_sp = wiki_sp[['Symbol']]\n",
    "\n",
    "    table2 = pd.read_html(url, header=0)\n",
    "    wiki_change = table1[1]\n",
    "    \n",
    "    sp_historic = pd.read_csv(sp_historic_path, sep='|')\n",
    "    sp_historic['date'] = pd.to_datetime(sp_historic['date'])\n",
    "    sp_historic['tickers'] = sp_historic['tickers'].apply(lambda x: sorted(x.split(',')))\n",
    "    \n",
    "    return wiki_sp, wiki_change, sp_historic\n",
    "\n",
    "\n",
    "def wiki_change_formatting(wiki_change):\n",
    "    # Drop extra header and unwanted cols\n",
    "    wiki_change = wiki_change.reset_index(drop=True)\n",
    "    wiki_change = wiki_change.drop(['Reason', 'Security'], axis=1, level=1)\n",
    "    bottom_headers = wiki_change.columns.get_level_values(0)\n",
    "    top_headers = wiki_change.columns.get_level_values(1)\n",
    "    wiki_change.columns = bottom_headers\n",
    "    # Rename Cols\n",
    "    wiki_change = wiki_change.rename(columns={'Date': 'date', 'Added': 'added', 'Removed': 'removed'})\n",
    "    # Fix date format\n",
    "    wiki_change['date'] = pd.to_datetime(wiki_change['date'])\n",
    "    wiki_change['date'] = wiki_change['date'].dt.strftime('%Y-%m-%d')\n",
    "    wiki_change['date'] = pd.to_datetime(wiki_change['date'])\n",
    "    # Filter off dates before current date\n",
    "    wiki_change = wiki_change.loc[wiki_change['date'] >= pd.to_datetime('2023-06-21')]\n",
    "    # Replace NaN values with None in 'Added' and 'Removed' columns\n",
    "    wiki_change['added'] = wiki_change['added'].fillna('None')\n",
    "    wiki_change['removed'] = wiki_change['removed'].fillna('None')\n",
    "    # Group by 'Date' column and combine 'Added' and 'Removed' values as a list\n",
    "    wiki_change = wiki_change.groupby('date').agg(lambda x: x.tolist()).reset_index()\n",
    "    # Sort by date\n",
    "    wiki_change = wiki_change.sort_values(by='date', ascending=True)\n",
    "    wiki_change = wiki_change.reset_index(drop=True)\n",
    "    \n",
    "    return wiki_change\n",
    "\n",
    "# Update sp_historic with changes from wiki_change    \n",
    "def historic_data_process(wiki_change, sp_historic):\n",
    "    for change in wiki_change.itertuples():\n",
    "        # Assign values\n",
    "        date = change.date\n",
    "        added_tickers = change.added\n",
    "        removed_tickers = change.removed\n",
    "\n",
    "        new_row = sp_historic.tail(1)\n",
    "        tickers = list(new_row['tickers'].values[0])\n",
    "\n",
    "        # Skip over 'None' values and proceed to next valid symbol in added_tickers\n",
    "        index = 0\n",
    "        while index < len(added_tickers):\n",
    "            ticker = added_tickers[index]\n",
    "            if ticker == 'None':\n",
    "                index += 1\n",
    "                continue\n",
    "            tickers.append(ticker)\n",
    "            index += 1\n",
    "\n",
    "        # Add or remove tickers in list    \n",
    "        tickers = list(set(tickers) - set(removed_tickers))\n",
    "        tickers = sorted(tickers)\n",
    "\n",
    "        # Store updates & concat\n",
    "        d = {'date': date, 'tickers': [tickers]}\n",
    "        new_entry = pd.DataFrame(d)\n",
    "        sp_historic = pd.concat([sp_historic, new_entry]).reset_index(drop=True)\n",
    "        \n",
    "    # Define ticker replacements\n",
    "    ticker_replacements = {\n",
    "    'PKI': 'RVTY',\n",
    "    'FISV': 'FI',\n",
    "    'RE': 'EG'\n",
    "    }\n",
    "    # Replace tickers with updated tickers\n",
    "    sp_historic['tickers'] = sp_historic['tickers'].apply(lambda x: sorted([ticker_replacements.get(ticker, ticker) for ticker in x]))\n",
    "    \n",
    "    # Formatting\n",
    "    # Fix date format\n",
    "    sp_historic['date'] = pd.to_datetime(sp_historic['date'])\n",
    "    sp_historic['date'] = sp_historic['date'].dt.strftime('%Y-%m-%d')\n",
    "    sp_historic['date'] = pd.to_datetime(sp_historic['date'])\n",
    "    sp_historic = sp_historic.sort_values(by='date')\n",
    "    # Resample with daily frequency\n",
    "    # Set 'date' column as the index\n",
    "    #sp_historic = sp_historic.set_index('date')\n",
    "    # Resample the dataframe with daily frequency and forward fill the missing values\n",
    "    #sp_historic = sp_historic.resample('D').ffill()\n",
    "    # Reset the index and restore 'date' as a column\n",
    "    #sp_historic = sp_historic.reset_index()\n",
    "    #sp_historic = sp_historic.sort_values('date')\n",
    "    \n",
    "    return sp_historic\n",
    "\n",
    "# Update sp_historic with corp actions\n",
    "def process_corporate_actions(sp_historic, s_changes_path):\n",
    "    # Update sp historic with corporate action ticker changes\n",
    "    s_changes = pd.read_csv(s_changes_path, sep='|')\n",
    "    s_changes = s_changes.sort_values(by='date', ascending=False)\n",
    "    s_changes = s_changes[s_changes['date'] <= '2023-06-20']\n",
    "    s_changes = s_changes.reset_index(drop=True)\n",
    "\n",
    "    # Group changes by day\n",
    "    grouped_changes = s_changes.groupby('date')\n",
    "\n",
    "    # Iterate over each day going back in time\n",
    "    for date, group in reversed(list(grouped_changes)):\n",
    "\n",
    "        # Get tickers for the day before the change date\n",
    "        prev_date = pd.to_datetime(date) - pd.DateOffset(days=1)\n",
    "        prev_day_tickers = sp_historic.loc[sp_historic['date'] == prev_date, 'tickers']\n",
    "        if prev_day_tickers.empty:\n",
    "            break\n",
    "        prev_day_tickers = prev_day_tickers.iloc[0]\n",
    "\n",
    "        removed_tickers = []\n",
    "        added_tickers = []\n",
    "        for index, row in group.iterrows():\n",
    "            symbol = row['symbol']\n",
    "            prev_symbol = row['prev_symbol']\n",
    "            if symbol in prev_day_tickers:\n",
    "                removed_tickers.append(symbol)\n",
    "                added_tickers.append(prev_symbol)\n",
    "\n",
    "        removed_tickers = set(removed_tickers)\n",
    "        added_tickers = set(added_tickers)\n",
    "    \n",
    "        # Find tickers only added or removed\n",
    "        unique_added = added_tickers - removed_tickers\n",
    "        unique_removed = removed_tickers - added_tickers\n",
    "\n",
    "        def corporate_action(row, unique_added, unique_removed, prev_day_tickers):\n",
    "            tickers = row\n",
    "            updated_tickers = list(set(tickers) - set(unique_removed))\n",
    "            updated_tickers += unique_added\n",
    "            return sorted(updated_tickers)\n",
    "            \n",
    "        # Update tickers in sp_historic for current day\n",
    "        sp_historic.loc[sp_historic['date'] < date, 'tickers'] = sp_historic.loc[sp_historic['date'] < date, 'tickers'].apply(lambda x: corporate_action(x, unique_added, unique_removed, prev_day_tickers))\n",
    "\n",
    "    # Sort sp_historic by date\n",
    "    sp_historic = sp_historic.sort_values(by='date').reset_index(drop=True)\n",
    "    \n",
    "    return sp_historic\n",
    "\n",
    "\n",
    "def main(url, sp_historical_path, s_changes_path):\n",
    "    wiki_sp, wiki_change, sp_historic = read_and_preprocess(url, sp_historic_path)\n",
    "    wiki_change = wiki_change_formatting(wiki_change)\n",
    "    sp_historic = historic_data_process(wiki_change, sp_historic)\n",
    "    \n",
    "    # Update with previous tickers if no changes from wiki sp\n",
    "    # Get today's date\n",
    "    today = pd.to_datetime('today').normalize()\n",
    "\n",
    "    # If the latest date in the data is before today, append today's data\n",
    "    if sp_historic['date'].iloc[-1] < today:\n",
    "        last_tickers = sp_historic['tickers'].iloc[-1]\n",
    "        new_row = {'date': today, 'tickers': last_tickers}\n",
    "        sp_historic = sp_historic.append(new_row, ignore_index=True)\n",
    "    \n",
    "    sp_historic = process_corporate_actions(sp_historic, s_changes_path)\n",
    "    \n",
    "    return sp_historic\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    sp_historic_path = '/home/rdoss/list_fixes/sp500_fix/output_check'\n",
    "    s_changes_path = '/home/rdoss/list_fixes/sp500_fix/ticker_changes.csv'\n",
    "    sp_historic = main(url, sp_historic_path, s_changes_path)\n",
    "    \n",
    "    print(sp_historic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
